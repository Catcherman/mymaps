* 2016 年 04 月 18 日
** ES 搜索
*** 不能查询的问题
**** 数据插入是否正确  正确
**** 服务启动是否正确 正确
**** 创建语法
***** 简单的写法——不添加 scheame 的方法是可以创建并插入数据的
***** 通用的创建方法——
**** 查询语法 
***** 原来使用的写法查询失败，　用新的写法可以查询（简单的写法）
***** 之前的所添加的功能
*** 使用 ES 搜索服务进行黑名单图书去重
**** 新建索引
**** DONE 添加、修改数据
     CLOSED: [2016-04-18 一 19:51]
**** 删除数据
**** 搜索数据
**** basehandler 中异常的捕获
** 榜单爬虫配置方法
*** 配置服务
*** 爬虫系统
** 腾讯图书内容获取
*** 获取图书详情链接
*** 章节链接
*** 获取内容
*** 防抓对策
**** 遇到的问题
     
* 2016 年 04 月 19 日
** ES 搜索
*** DONE 配置，onling 和 gray
    CLOSED: [2016-04-19 二 09:38]
*** DONE 创建索引逻辑
    CLOSED: [2016-04-19 二 10:05]
*** DONE 测试
    CLOSED: [2016-04-20 三 15:03]
*** DONE 上线
    CLOSED: [2016-04-20 三 15:03]
*** 注释格式
*** basehandler 的异常捕获
** 榜单爬虫配置方法
*** 配置服务
*** 爬虫系统
** 腾讯图书内容获取
*** 获取图书详情链接
*** 章节链接
*** 获取内容
*** 防抓对策
**** 遇到的问题
* 2016 年 04 月 20 日
** 腾讯图书内容获取
*** 获取图书详情链接
*** 章节链接
*** 获取内容
*** 防抓对策
**** 遇到的问题
** 榜单爬虫配置方法
*** 配置服务
*** 爬虫系统
** ES 搜索
*** basehandler 的异常捕获
*** 注释格式
** 漫画抓取重启
* 2016 年 04 月 21 日
** 腾讯图书内容获取
*** DONE 获取图书详情链接
    CLOSED: [2016-04-22 五 10:03]
*** 章节链接
*** 获取内容
*** 防抓对策
**** 遇到的问题
** 榜单爬虫配置方法
*** 配置服务
**** url, title, is_vip, chapter_updatetime, chapter_item
**** 载新增的时候能找到五个 不包括 chapter_item
**** chapter_item 返回章节 item 列表
**** 和正规从 item 获取数据不同，这里直接写 tagname 开始就行
*** 爬虫系统
**** 
**** 列表分页
*** 网站
**** DONE 已有
     CLOSED: [2016-04-21 四 15:13]
***** 17k
***** 香网
***** 言情书殿
***** 逸云
***** 原创
***** 逐浪网
***** 纵横
**** 逐浪（已经做过）
**** 纵横 (已经做过)
**** 3G 门户
**** 塔读
**** 晋江
**** 中文在线
** ES 搜索
*** basehandler 的异常捕获
*** 注释格式
** 漫画抓取重启
* 2016 年 04 月 21 日
** 腾讯图书内容获取
*** 章节链接
*** 获取内容
*** 防抓对策
**** 遇到的问题
** 榜单爬虫配置方法
*** 配置服务
**** url, title, is_vip, chapter_updatetime, chapter_item
**** 载新增的时候能找到五个 不包括 chapter_item
**** chapter_item 返回章节 item 列表
**** 和正规从 item 获取数据不同，这里直接写 tagname 开始就行
*** 爬虫系统
**** 列表分页
*** 网站
**** DONE 已有
     CLOSED: [2016-04-21 四 15:13]
***** 17k
***** 香网
***** 言情书殿
***** 逸云
***** 原创
***** 逐浪网
***** 纵横
**** 要做
***** 3G 门户
***** 塔读
***** 晋江
***** 中文在线
** ES 搜索
*** basehandler 的异常捕获
*** 注释格式
** 漫画抓取重启
* 2016 年 04 月 25 日
** 腾讯图书内容获取
*** 章节链接
*** 获取内容
*** 防抓对策
**** 遇到的问题
** 榜单爬虫配置方法
*** 配置服务
**** url, title, is_vip, chapter_updatetime, chapter_item
**** 载新增的时候能找到五个 不包括 chapter_item
**** chapter_item 返回章节 item 列表
**** 和正规从 item 获取数据不同，这里直接写 tagname 开始就行
*** 爬虫系统
**** 列表分页
*** 网站
**** 要做
***** DONE 3G 门户
      CLOSED: [2016-04-26 二 19:40]
***** DONE 塔读
      CLOSED: [2016-04-26 二 20:48]
***** DONE 晋江
      CLOSED: [2016-04-27 三 09:39]
** ES 搜索
*** basehandler 的异常捕获
*** 注释格式
** 漫画抓取重启
* 2016 年 04 月 26 日
** 腾讯图书内容获取
*** 章节链接
*** 获取内容
*** 防抓对策
**** 遇到的问题
**** 帐号
** 榜单爬虫配置方法
*** 配置服务
**** url, title, is_vip, chapter_updatetime, chapter_item
**** 载新增的时候能找到三个 不包括 chapter_item
**** chapter_item 返回章节 item 列表
**** 和正规从 item 获取数据不同，这里直接写 tagname 开始就行
*** 爬虫系统
**** 列表分页
*** 网站
**** 要做
***** DONE 磨铁
      CLOSED: [2016-04-27 三 10:36]
** ES 搜索
*** basehandler 的异常捕获
*** 注释格式
** 漫画抓取重启

* 2016 年 04 月 27 日
** 腾讯图书内容获取
***  设计
**** scrapy 组件, multiprocessing, 定义的 spider
**** 基础 spider, 
**** 各自需要独自实现的方法
**** 帐号登录解决
**** 
*** 章节链接
*** 获取内容
*** 防抓对策
**** 遇到的问题
**** 帐号
** 榜单爬虫配置方法
*** 配置服务
**** url, title, is_vip, chapter_updatetime, chapter_item
**** 载新增的时候能找到三个 不包括 chapter_item
**** chapter_item 返回章节 item 列表
**** 和正规从 item 获取数据不同，这里直接写 tagname 开始就行
*** 爬虫系统
**** 列表分页
*** 网站
**** 要做
***** DONE 磨铁
      CLOSED: [2016-04-27 三 10:36]
** ES 搜索
*** basehandler 的异常捕获
*** 注释格式
** 漫画抓取重启
** 源码阅读
*** scrapy
*** requests
*** grequests
*** zyorm
* 2016 年 05 月 02 日
** 腾讯图书内容获取
***  设计
**** 帐号登录解决
**** 各自需要独自实现的方法
*** 防抓对策
**** 遇到的问题
**** 帐号----自动登录
** 漫画抓取重启
** 榜单爬虫配置方法
*** 配置服务
**** url, title, is_vip, chapter_updatetime, chapter_item
**** 载新增的时候能找到三个 不包括 chapter_item
**** chapter_item 返回章节 item 列表
**** 和正规从 item 获取数据不同，这里直接写 tagname 开始就行
*** 爬虫系统
**** 列表分页
*** 网站
**** 要做
***** 四个网站
** ES 搜索
*** basehandler 的异常捕获
*** 注释格式
** 源码阅读
*** scrapy
*** requests
*** grequests
*** zyorm
* 2016 年 05 月 03 日
** 腾讯图书内容获取
***  设计
**** 帐号登录解决
**** 各自需要独自实现的方法
*** 防抓对策
**** 遇到的问题
**** 帐号----自动登录
** 漫画抓取重启
** 榜单爬虫配置方法
*** 配置服务
**** url, title, is_vip, chapter_updatetime, chapter_item
**** 载新增的时候能找到三个 不包括 chapter_item
**** chapter_item 返回章节 item 列表
**** 和正规从 item 获取数据不同，这里直接写 tagname 开始就行
*** 爬虫系统
**** 列表分页
*** 网站
**** 要做
***** 四个网站
** ES 搜索
*** basehandler 的异常捕获
*** 注释格式
** 源码阅读
*** scrapy
*** requests
*** grequests
*** zyorm
* 2016 年 05 月 04 日
** 腾讯图书内容获取
***  设计
**** 帐号登录解决
**** 各自需要独自实现的方法
*** 防抓对策
**** 遇到的问题
**** 帐号----自动登录
** 漫画抓取重启
** 榜单爬虫配置方法
*** 配置服务
**** url, title, is_vip, chapter_updatetime, chapter_item
**** 载新增的时候能找到三个 不包括 chapter_item
**** chapter_item 返回章节 item 列表
**** 和正规从 item 获取数据不同，这里直接写 tagname 开始就行
*** 爬虫系统
**** 列表分页
*** 网站
**** 要做
***** 四个网站
***** DONE 京东全站
      CLOSED: [2016-05-05 四 12:08]
***** DONE 豆瓣全站
      CLOSED: [2016-05-06 五 11:00]
** ES 搜索
*** basehandler 的异常捕获
*** 注释格式
** 文档阅读
*** pyspider
*** scrapy
** 源码阅读
*** scrapy
*** requests
*** TODO grequests
*** zyorm
* 2016 年 05 月 05 日
** 腾讯图书内容获取
***  设计
**** 帐号登录解决
**** 各自需要独自实现的方法
*** 防抓对策
**** 遇到的问题
**** 帐号----自动登录
** 漫画抓取重启
** 榜单爬虫配置方法
*** 配置服务
**** url, title, is_vip, chapter_updatetime, chapter_item
**** 载新增的时候能找到三个 不包括 chapter_item
**** chapter_item 返回章节 item 列表
**** 和正规从 item 获取数据不同，这里直接写 tagname 开始就行
*** 爬虫系统
**** 列表分页
*** 网站
**** 要做
***** 四个网站
** ES 搜索
*** basehandler 的异常捕获
*** 注释格式
** 文档阅读
*** pyspider
*** scrapy
** 源码阅读
*** scrapy
*** requests
*** TODO grequests
*** zyorm
* 2016 年 05 月 09 日
** 腾讯图书内容获取
***  设计
**** 帐号登录解决
**** 各自需要独自实现的方法
*** 防抓对策
**** 遇到的问题
**** 帐号----自动登录
** 漫画抓取重启
** 榜单爬虫配置方法
*** 配置服务
**** url, title, is_vip, chapter_updatetime, chapter_item
**** 载新增的时候能找到三个 不包括 chapter_item
**** chapter_item 返回章节 item 列表
**** 和正规从 item 获取数据不同，这里直接写 tagname 开始就行
*** 爬虫系统
**** 列表分页
*** 网站
**** 要做
***** 四个网站
** ES 搜索
*** basehandler 的异常捕获
*** 注释格式
** 文档阅读
*** pyspider
*** scrapy
** 源码阅读
*** scrapy
*** requests
*** TODO grequests
*** zyorm
* 2016 年 05 月 10 日
** DONE 腾讯图书内容获取
   CLOSED: [2016-05-10 二 15:18]   抓了腾讯文学一个网站的书，其他的网站要他们冲费也不冲，那就这样龙。
***  设计
**** 各自需要独自实现的方法
*** 防抓对策
**** 遇到的问题
**** 帐号----自动登录
** 漫画抓取重启
** 榜单爬虫配置方法
*** 配置服务
**** url, title, is_vip, chapter_updatetime, chapter_items
**** 载新增的时候能找到三个 不包括 chapter_items
**** chapter_items 返回章节 item 列表
**** 在全站爬虫添加 chapter_list_project
*** 爬虫系统
**** 列表分页
*** 网站
**** 要做
***** DONE 四个网站
      CLOSED: [2016-05-10 二 15:12]
     - 二层楼
     - 风鸣轩
     - 蔷薇书院
     - 甜悦读
**** 风鸣轩全站
** ES 搜索
*** basehandler 的异常捕获
*** 注释格式
*** 吧修改的代码提交上去
** 文档阅读
*** pyspider
*** scrapy
** 源码阅读
*** scrapy
*** requests
*** TODO grequests
*** zyorm
* 2016 年 05 月 11 日
** 漫画抓取重启
** DONE 提交代码评审的结果
   CLOSED: [2016-05-12 四 12:13]
** 榜单爬虫配置方法
*** 配置服务
**** url, title, is_vip, chapter_updatetime, chapter_items
**** 载新增的时候能找到三个 不包括 chapter_items
**** chapter_items 返回章节 item 列表
**** 在全站爬虫添加 chapter_list_project
*** 爬虫系统
**** 列表分页
*** 网站
**** 要做
**** 风鸣轩全站
** ES 搜索
*** basehandler 的异常捕获
*** 注释格式
*** 吧修改的代码提交上去
** 文档阅读
*** pyspider
*** scrapy
** 源码阅读
*** scrapy
*** requests
*** TODO grequests
*** zyorm
* 2016 年 05 月 12 日
** 榜单爬虫配置方法
*** 配置服务
**** url, title, is_vip, chapter_updatetime, chapter_items
**** 载新增的时候能找到三个 不包括 chapter_items
**** chapter_items 返回章节 item 列表
**** 在全站爬虫添加 chapter_list_project
*** 爬虫系统
**** 列表分页
*** 网站
**** 要做
     - hongshu
     - xs8
     - huayu
     - kanshu
     - tiandi
**** 风鸣轩全站
** ES 搜索
*** basehandler 的异常捕获
*** 注释格式
*** 吧修改的代码提交上去
** 添加清洗服务方法
** 文档阅读
*** pyspider
*** scrapy
** 源码阅读
*** scrapy
*** requests
*** TODO grequests
*** zyorm
** 漫画抓取重启
* 2016 年 05 月 17 日
** 清洗服务
*** 确定要配置哪些爬虫的清晰服务
*** 重新确定清洗服务测试的使用方法
*** 配置清洗服务
** ES 搜索
*** basehandler 的异常捕获
*** 注释格式
*** 吧修改的代码提交上去
** 添加清洗服务方法
** 文档阅读
*** pyspider
*** scrapy
** 源码阅读
*** scrapy
*** requests
*** TODO grequests
*** zyorm
** 漫画抓取重启
* 2016 年 05 月 19 日
** 豆瓣榜单
*** DONE 那些榜单
    CLOSED: [2016-05-19 四 11:13]
*** 抓取榜单定时发邮件
*** 匹配亚马逊的品牌（找到原代码）
** 清洗服务
*** 确定要配置哪些爬虫的清晰服务
*** 重新确定清洗服务测试的使用方法
*** 配置清洗服务
** ES 搜索
*** basehandler 的异常捕获
*** 注释格式
*** 吧修改的代码提交上去
** 添加清洗服务方法
** 文档阅读
*** pyspider
*** scrapy
** 源码阅读
*** scrapy
*** requests
*** TODO grequests
*** TODO zyorm
** 漫画抓取重启
* 2016 年 05 月 23 日
** DONE 图书上架失败问题查询
   CLOSED: [2016-05-24 二 09:56]
*** 1.只有这一本图书有问题
*** 10133149
*** 提示：通知运营异常(提示消息不准确)
*** 运营那边的问题（他们 orm 添加了一个字段，和数据库不对应，所以报错）
** 豆瓣榜单
*** DONE 那些榜单
    CLOSED: [2016-05-19 四 11:13]
*** 抓取榜单定时发邮件
*** 匹配亚马逊的品牌（找到原代码）
** 清洗服务
*** 确定要配置哪些爬虫的清晰服务
*** 重新确定清洗服务测试的使用方法
*** 配置清洗服务
** ES 搜索
*** basehandler 的异常捕获
*** 注释格式
*** 吧修改的代码提交上去
** 添加清洗服务方法
** 文档阅读
*** pyspider
*** scrapy
** 源码阅读
*** scrapy
*** requests
*** TODO grequests
*** TODO zyorm
** 漫画抓取重启
* 2016 年 05 月 24 日
** DONE 当当榜单
   CLOSED: [2016-06-06 一 15:10] DEADLINE: <2016-06-06 一 15:07>
*** 那些榜单
*** 抓取榜单定时发邮件
*** 匹配亚马逊的品牌（找到原代码）
** 清洗服务
*** 确定要配置哪些爬虫的清晰服务
*** 重新确定清洗服务测试的使用方法
*** 配置清洗服务
** ES 搜索
*** basehandler 的异常捕获
*** 注释格式
*** 吧修改的代码提交上去
** DONE 添加清洗服务方法
   CLOSED: [2016-06-06 一 15:11]
** 文档阅读
*** pyspider
*** scrapy
** 源码阅读
*** scrapy
*** requests
*** TODO grequests
*** TODO zyorm
** 漫画抓取重启

* 2016 年 06 月 06 日
** zyspider 爬虫
*** 确定要配置哪些网站的全站和榜单爬虫
*** 配置全站爬虫,榜单爬虫,章节爬虫,清洗服务
** 文档阅读
*** pyspider
*** scrapy
** 源码阅读
*** scrapy
*** requests
*** TODO grequests
*** TODO zyorm
** 漫画抓取重启
** ES 搜索
*** basehandler 的异常捕获
*** 注释格式
*** 吧修改的代码提交上去
    
